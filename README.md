# My-Main-Projects
This repository contains a selection of my best and most advanced ML and Deep Learning projects

---

| **Project** | **Scores** |
|---|---|
| 1. Breast Cancer Classification using Computer Vision in Keras | **95% F1_score** |
| 2. Real-Time Car Price Recommendation Engine built on Spark Streaming in Databricks | **2350$ Mean Average Error** |
| 3. Customer Credit Score Classification using Random Forest in R | **98% Multivariate AUC** |
| 4. Text Sentiment Analysis and Topic Classification of Restaurant Reviews in Python | **85% Correlation | 61% F1_score** |
| 5. Human Obesity Classification using Boosting Classifier in Python | **95% F1_score** |

---

### **1. Breast Cancer Classification using Computer Vision in Keras** 
[dataset #1](https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis) \
 \
 This is a project that we loved

### **2. Used Cars Price Recommendation Engine built on Spark Streaming in Databricks** 
[dataset #2](https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data) \
 \
 This is a project that we loved

### **3. Customer Credit Score Classification using Random Forest in R** 
[dataset #3](https://www.kaggle.com/datasets/parisrohan/credit-score-classification) \
 \
This project aimed to develop a classification model to predict the credit score of clients applying for loans at a bank based on a set of provided features. To address class imbalance, SMOTE oversampling was employed to augment the minority class. The model was optimized using a grid search algorithm and its performance was assessed with the ROC (Receiver Operating Characteristic) Area Under the Curve (AUC) metric.

### **4. Text Sentiment Analysis and Topic Classification of Restaurant Reviews in Python** 
dataset #4 - data available inside the folder \
 \
 This is a project that we loved

### **5. Human Obesity Classification using Boosting Classifier in Python** 
dataset #5 - data available inside the folder \
\
This project focused on classifying the stages of human obesity based on a variety of features, including weight, height, age, gender, and lifestyle-related factors. To handle missing data, K-Nearest Neighbors (KNN) was used to impute numerical features, while the Iterative Imputer was employed to fill in missing categorical values. Among the models tested, Gradient Boosting emerged as the most accurate, achieving high F1 scores, with performance evaluated using Stratified K-Fold Cross-Validation.
